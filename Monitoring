import os
import json
import logging
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt

# -------------------------------------------------
# CONFIGURATION (edit as needed)
# -------------------------------------------------
pred_path       = r"\\uknasdata08\FSSHARED\WIP\Credit Risk Assurance\Engagements\XXXXX\YE25\4. Data and Codes\ECL Engine Code\MNF\Recoded_Hitesh\Output\7a\Base_Values_EAD.csv"
actuals_path    = r"\\uknasdata08\FSSHARED\WIP\Credit Risk Assurance\Engagements\XXXXX\YE25\4. Data and Codes\ECL Engine Code\MNF\Recoded_Hitesh\Actuals\actuals.csv"
out_dir         = r"\\uknasdata08\FSSHARED\WIP\Credit Risk Assurance\Engagements\XXXXX\YE25\4. Data and Codes\ECL Engine Code\MNF\Recoded_Hitesh\Monitoring\2025-08-12"

key_col         = "account_id"
pred_ead12_col  = "EAD_12m"
pred_eadlt_col  = "EAD_LT"
act_ead12_col   = "Actual_EAD_12m"
act_eadlt_col   = "Actual_EAD_LT"
segments_str    = "Portfolio,Term_Bucket,TOB_Bucket"   # "" if none
score_ref_path  = None                                 # optional
score_col       = None                                 # optional

# -------------------------------------------------
# SETUP
# -------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

if not os.path.exists(out_dir):
    os.makedirs(out_dir)

logging.info("Reading data")
df_pred = pd.read_csv(pred_path)
df_act = pd.read_csv(actuals_path)

# Check required columns
for col in [key_col, pred_ead12_col, pred_eadlt_col]:
    if col not in df_pred.columns:
        raise ValueError(f"Missing {col} in predictions")
for col in [key_col, act_ead12_col, act_eadlt_col]:
    if col not in df_act.columns:
        raise ValueError(f"Missing {col} in actuals")

# Merge
df = df_pred.merge(df_act, on=key_col, how="inner", suffixes=("", "_act"))
if df.empty:
    logging.warning("Merged dataframe is empty")

# -------------------------------------------------
# GLOBAL METRICS
# -------------------------------------------------
def metrics(y, p):
    y = np.asarray(y, dtype=float)
    p = np.asarray(p, dtype=float)
    diff = p - y
    rmse = np.sqrt(np.nanmean(diff ** 2))
    mae = np.nanmean(np.abs(diff))
    mape = np.nanmean(np.abs(diff) / np.where(y == 0, np.nan, np.abs(y))) * 100
    ss_res = np.nansum(diff ** 2)
    ss_tot = np.nansum((y - np.nanmean(y)) ** 2)
    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan
    return rmse, mae, mape, r2

rows = []
for pred_col, act_col, label in [
    (pred_ead12_col, act_ead12_col, "EAD_12m"),
    (pred_eadlt_col, act_eadlt_col, "EAD_LT")
]:
    rmse, mae, mape, r2 = metrics(df[act_col], df[pred_col])
    rows.append({
        "target": label,
        "RMSE": rmse, "MAE": mae, "MAPE": mape, "R2": r2,
        "n": len(df),
        "actual_sum": df[act_col].sum(skipna=True),
        "pred_sum": df[pred_col].sum(skipna=True),
        "bias_sum": df[pred_col].sum(skipna=True) - df[act_col].sum(skipna=True)
    })
global_metrics = pd.DataFrame(rows)
global_metrics.to_csv(os.path.join(out_dir, "global_metrics.csv"), index=False)

# -------------------------------------------------
# CALIBRATION TABLES + PLOTS
# -------------------------------------------------
def decile_table(df, pred_col, act_col, n=10):
    rank = df[pred_col].rank(method="first", na_option="keep")
    deciles = pd.qcut(rank, q=n, labels=False, duplicates="drop") + 1
    tmp = df.assign(decile=deciles)
    out = tmp.groupby("decile", dropna=False).agg(
        count=(pred_col, "size"),
        pred_mean=(pred_col, "mean"),
        actual_mean=(act_col, "mean"),
        pred_sum=(pred_col, "sum"),
        actual_sum=(act_col, "sum"),
    ).reset_index()
    out["bias_sum"] = out["pred_sum"] - out["actual_sum"]
    out["bias_pct"] = np.where(out["actual_sum"] == 0, np.nan, out["bias_sum"] / out["actual_sum"]) * 100
    return out

def plot_calibration(df_dec, title, path):
    plt.figure()
    plt.plot(df_dec["decile"], df_dec["pred_mean"], marker="o", label="Pred mean")
    plt.plot(df_dec["decile"], df_dec["actual_mean"], marker="o", label="Actual mean")
    plt.xlabel("Decile")
    plt.ylabel("Mean value")
    plt.title(title)
    plt.legend()
    plt.tight_layout()
    plt.savefig(path)
    plt.close()

def plot_bias(df_dec, title, path):
    plt.figure()
    plt.bar(df_dec["decile"], df_dec["bias_sum"])
    plt.xlabel("Decile")
    plt.ylabel("Pred - Actual sum")
    plt.title(title)
    plt.tight_layout()
    plt.savefig(path)
    plt.close()

for pred_col, act_col, label in [
    (pred_ead12_col, act_ead12_col, "EAD_12m"),
    (pred_eadlt_col, act_eadlt_col, "EAD_LT")
]:
    dec = decile_table(df, pred_col, act_col)
    dec.to_csv(os.path.join(out_dir, f"calibration_{label}.csv"), index=False)
    plot_calibration(dec, f"Calibration {label}", os.path.join(out_dir, f"calibration_curve_{label}.png"))
    plot_bias(dec, f"Bias by decile {label}", os.path.join(out_dir, f"bias_by_decile_{label}.png"))

# -------------------------------------------------
# SEGMENT REPORT
# -------------------------------------------------
segments = [s.strip() for s in segments_str.split(",") if s.strip()]
seg_cols = [c for c in segments if c in df.columns]
rows = []

if not seg_cols:
    groups = [("", df)]
else:
    groups = list(df.groupby(seg_cols, dropna=False))

for seg_key, g in tqdm(groups, desc="Segments"):
    for pred_col, act_col in [
        (pred_ead12_col, act_ead12_col),
        (pred_eadlt_col, act_eadlt_col)
    ]:
        rmse, mae, mape, r2 = metrics(g[act_col], g[pred_col])
        entry = {}
        if seg_cols:
            if isinstance(seg_key, tuple):
                for c, v in zip(seg_cols, seg_key):
                    entry[c] = v
            else:
                entry[seg_cols[0]] = seg_key
        entry.update({
            "pred_col": pred_col,
            "actual_col": act_col,
            "RMSE": rmse, "MAE": mae, "MAPE": mape, "R2": r2,
            "n": len(g),
            "actual_sum": g[act_col].sum(skipna=True),
            "pred_sum": g[pred_col].sum(skipna=True),
            "bias_sum": g[pred_col].sum(skipna=True) - g[act_col].sum(skipna=True)
        })
        rows.append(entry)

seg_report = pd.DataFrame(rows)
seg_report.to_csv(os.path.join(out_dir, "segment_report.csv"), index=False)

# -------------------------------------------------
# PSI (optional)
# -------------------------------------------------
psi_path = None
if score_ref_path and score_col and os.path.exists(score_ref_path) and score_col in df.columns:
    df_ref = pd.read_csv(score_ref_path)
    if score_col in df_ref.columns:
        train_scores = np.asarray(df_ref[score_col], dtype=float)
        monitor_scores = np.asarray(df[score_col], dtype=float)
        qs = np.nanquantile(train_scores, np.linspace(0, 1, 11))
        qs[0], qs[-1] = -np.inf, np.inf
        def bins(x):
            cats = pd.cut(x, bins=qs, include_lowest=True)
            vc = cats.value_counts(normalize=True, sort=False)
            return vc.reindex(pd.IntervalIndex.from_breaks(qs), fill_value=0.0).values
        psi_val = float(np.sum((bins(monitor_scores) - bins(train_scores)) *
                               np.log(bins(monitor_scores) / bins(train_scores))))
        psi_path = os.path.join(out_dir, "psi.json")
        with open(psi_path, "w") as f:
            json.dump({"score_col": score_col, "PSI": psi_val}, f, indent=2)

# -------------------------------------------------
# INDEX MANIFEST
# -------------------------------------------------
index = {
    "global_metrics_csv": os.path.join(out_dir, "global_metrics.csv"),
    "calibration": {
        "EAD_12m": {
            "table": os.path.join(out_dir, "calibration_EAD_12m.csv"),
            "curve_png": os.path.join(out_dir, "calibration_curve_EAD_12m.png"),
            "bias_png": os.path.join(out_dir, "bias_by_decile_EAD_12m.png"),
        },
        "EAD_LT": {
            "table": os.path.join(out_dir, "calibration_EAD_LT.csv"),
            "curve_png": os.path.join(out_dir, "calibration_curve_EAD_LT.png"),
            "bias_png": os.path.join(out_dir, "bias_by_decile_EAD_LT.png"),
        }
    },
    "segment_report_csv": os.path.join(out_dir, "segment_report.csv"),
    "psi_json": psi_path
}

with open(os.path.join(out_dir, "index.json"), "w") as f:
    json.dump(index, f, indent=2)

logging.info("Monitoring completed")
print(json.dumps(index, indent=2))